import pandas as pd
import lightgbm as lgb
from lightgbm import early_stopping, log_evaluation
from sklearn.model_selection import train_test_split
from sklearn.metrics import log_loss, roc_auc_score
import matplotlib.pyplot as plt

# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('data/train.csv')  # ê²½ë¡œëŠ” ìƒí™©ì— ë§ê²Œ ì¡°ì •

# 2. ì‚¬ìš©í•˜ì§€ ì•Šì„ ì»¬ëŸ¼ ì œê±°
drop_cols = ['inning_topbot']  # ì˜ë¯¸ ì—†ë‹¤ê³  íŒë‹¨í•œ í”¼ì²˜
X = df.drop(columns=drop_cols + ['k'])  # ë¼ë²¨ì€ 'k'
y = df['k']

# categorical columns ì²˜ë¦¬
cat_cols = ['pitch_type', 'pitch_name', 'stand', 'p_throws']
for col in cat_cols:
    X[col] = X[col].astype('category')


# 4. í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„ë¦¬
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# 5. LightGBM Datasetìœ¼ë¡œ ë³€í™˜
train_data = lgb.Dataset(X_train, label=y_train)
val_data = lgb.Dataset(X_val, label=y_val)

# 6. ëª¨ë¸ íŒŒë¼ë¯¸í„° ì„¤ì •
params = {
    'objective': 'binary',
    'metric': 'binary_logloss',
    'boosting_type': 'gbdt',
    'learning_rate': 0.05,
    'num_leaves': 31,
    'seed': 42
}

# 7. ëª¨ë¸ í•™ìŠµ

model = lgb.train(
    params,
    train_data,
    valid_sets=[val_data],
    callbacks=[
        early_stopping(stopping_rounds=20),
        log_evaluation(period=50)  # 50ë§ˆë‹¤ ë¡œê·¸ ì°ìŒ
    ]
)

# 8. ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_val)
print("ğŸ“‰ Log Loss:", log_loss(y_val, y_pred))
print("ğŸ“ˆ ROC AUC:", roc_auc_score(y_val, y_pred))

# 9. í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™”
lgb.plot_importance(model)
plt.title("Feature Importance")
plt.tight_layout()
plt.show()
